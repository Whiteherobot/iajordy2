{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425ded43",
   "metadata": {},
   "source": [
    "YOLO Model Configuration and Setup\n",
    "\n",
    "This notebook defines the YOLO model architecture and training hyperparameters for Pascal VOC 2012 dataset. It is configuration-only - prepares all parameters for training in notebook 03. No training execution here.\n",
    "\n",
    "Configuration Coverage:\n",
    "1. YOLO model selection (v8n - nano variant)\n",
    "2. Dataset and class definition (3 classes: person, car, dog from Pascal VOC)\n",
    "3. data.yaml configuration with normalized bounding boxes\n",
    "4. Model architecture parameters (input size 416x416, batch size 16)\n",
    "5. Training hyperparameters optimized for large dataset (50 epochs)\n",
    "6. Reproducibility settings (seed 42)\n",
    "\n",
    "Dataset: Pascal VOC 2012 (~3000-5000 images after filtering)\n",
    "Training Time: 30-60 minutes on GPU, 3-4 hours on CPU\n",
    "Output: Model ready for inference in notebook 04\n",
    "\n",
    "This notebook is prerequisite for notebook 03_training.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4170be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO MODEL CONFIGURATION\n",
      "============================================================\n",
      "Project Root: ..\n",
      "Data Dir: ..\\data\n",
      "Models Dir: ..\\models\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Project structure\n",
    "PROJECT_ROOT = Path('../')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"YOLO MODEL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Dir: {DATA_DIR}\")\n",
    "print(f\"Models Dir: {MODELS_DIR}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3c548",
   "metadata": {},
   "source": [
    "Stage 1: Environment Setup and Paths\n",
    "\n",
    "This stage initializes the Python environment by setting up file paths and directories required for the training configuration.\n",
    "\n",
    "Configuration components:\n",
    "- SEED: Fixed random seed (42) for reproducibility across runs\n",
    "- PROJECT_ROOT: Base directory containing all project files\n",
    "- DATA_DIR: Location of prepared YOLO dataset from notebook 01\n",
    "- MODELS_DIR: Directory where trained models will be saved\n",
    "\n",
    "All paths use pathlib.Path for cross-platform compatibility (Windows, Linux, macOS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbff3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Model Selection\n",
      "------------------------------------------------------------\n",
      "Model: yolov8n\n",
      "Pretrained: COCO\n",
      "Weights: yolov8n.pt\n",
      "Architecture: Nano (efficient, fast)\n",
      "Use case: Object detection with 3 classes\n"
     ]
    }
   ],
   "source": [
    "# Model selection\n",
    "MODEL_NAME = 'yolov8n'\n",
    "PRETRAINED_WEIGHTS = 'yolov8n.pt'\n",
    "\n",
    "print(\"\\n[1] Model Selection\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Pretrained: COCO\")\n",
    "print(f\"Weights: {PRETRAINED_WEIGHTS}\")\n",
    "print(f\"Architecture: Nano (efficient, fast)\")\n",
    "print(f\"Use case: Object detection with 3 classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66920ece",
   "metadata": {},
   "source": [
    "Stage 2: Model Selection\n",
    "\n",
    "This stage specifies the YOLO model architecture and pretrained weights to use.\n",
    "\n",
    "YOLOv8 variants by size:\n",
    "- yolov8n (nano): 3.2M parameters - fast and efficient\n",
    "- yolov8s (small): 11.2M parameters - balanced speed/accuracy\n",
    "- yolov8m (medium): 25.9M parameters - good accuracy\n",
    "- yolov8l (large): 43.7M parameters - high accuracy\n",
    "- yolov8x (xlarge): 68.2M parameters - best accuracy but slower\n",
    "\n",
    "This notebook uses yolov8n because:\n",
    "1. Lightweight for remote environments with limited resources\n",
    "2. Pretrained on COCO (80 classes) provides good transfer learning base\n",
    "3. Will be fine-tuned to our 3-class detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d694292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Dataset Configuration\n",
      "------------------------------------------------------------\n",
      "Number of classes: 3\n",
      "Classes: person, car, dog\n",
      "Format: YOLO (normalized bounding boxes)\n",
      "Splits: train, val, test\n",
      "\n",
      "Class IDs:\n",
      "  0: person\n",
      "  1: car\n",
      "  2: dog\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "NUM_CLASSES = 3\n",
    "CLASS_NAMES = ['person', 'car', 'dog']\n",
    "CLASS_MAPPING = {i: name for i, name in enumerate(CLASS_NAMES)}\n",
    "\n",
    "print(\"\\n[2] Dataset Configuration\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Classes: {', '.join(CLASS_NAMES)}\")\n",
    "print(f\"Format: YOLO (normalized bounding boxes)\")\n",
    "print(f\"Splits: train, val, test\")\n",
    "print(\"\\nClass IDs:\")\n",
    "for class_id, class_name in CLASS_MAPPING.items():\n",
    "    print(f\"  {class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160d36b",
   "metadata": {},
   "source": [
    "Stage 3: Dataset Configuration\n",
    "\n",
    "This stage defines the dataset composition and class mappings for the training task.\n",
    "\n",
    "Dataset specification:\n",
    "- NUM_CLASSES: 3 target object classes\n",
    "- CLASS_NAMES: Names of classes (person, car, dog)\n",
    "- Format: YOLO normalized bounding boxes (as prepared in notebook 01)\n",
    "\n",
    "Class ID mapping:\n",
    "- Class ID is the index position in CLASS_NAMES list\n",
    "- Stored in first column of label files\n",
    "- Used by YOLO model to identify object categories during training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a6252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Data Configuration (data.yaml)\n",
      "------------------------------------------------------------\n",
      "Path: ..\\data\\data.yaml\n",
      "\n",
      "Content:\n",
      "path: c:\\Users\\mlata\\Documents\\iajordy2\\notebooks\\..\\data\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: images/test\n",
      "nc: 3\n",
      "names:\n",
      "- person\n",
      "- car\n",
      "- dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create/Update data.yaml for YOLO\n",
    "data_yaml_path = DATA_DIR / 'data.yaml'\n",
    "\n",
    "data_yaml_content = {\n",
    "    'path': str(DATA_DIR.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': NUM_CLASSES,\n",
    "    'names': CLASS_NAMES\n",
    "}\n",
    "\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"\\n[3] Data Configuration (data.yaml)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Path: {data_yaml_path}\")\n",
    "print(f\"\\nContent:\")\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a3f66",
   "metadata": {},
   "source": [
    "Stage 4: Data Configuration File Generation\n",
    "\n",
    "This stage creates the data.yaml file, which is the interface between the dataset and YOLO training.\n",
    "\n",
    "data.yaml is required by YOLO and specifies:\n",
    "- path: Absolute path to dataset base directory\n",
    "- train: Relative path to training images\n",
    "- val: Relative path to validation images\n",
    "- test: Relative path to test images\n",
    "- nc: Number of classes\n",
    "- names: List of class names\n",
    "\n",
    "This file is created during notebook 01 but verified/recreated here for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9242dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] Training Hyperparameters\n",
      "------------------------------------------------------------\n",
      "Configuration (to be used in notebook 03):\n",
      "  epochs: 50\n",
      "  batch_size: 16\n",
      "  imgsz: 416\n",
      "  patience: 10\n",
      "  device: cuda\n",
      "  seed: 42\n",
      "  lr0: 0.01\n",
      "  lrf: 0.01\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  warmup_epochs: 3.0\n",
      "  warmup_momentum: 0.8\n",
      "  verbose: True\n",
      "  save: True\n",
      "  exist_ok: True\n",
      "\n",
      "============================================================\n",
      "Configuration complete\n",
      "Ready for training in notebook 03_training.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Training hyperparameters (to be used in notebook 03)\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 50,\n",
    "    'batch_size': 16,\n",
    "    'imgsz': 416,\n",
    "    'patience': 10,\n",
    "    'device': 'cuda',  # or 'cpu' if GPU not available\n",
    "    'seed': SEED,\n",
    "    'lr0': 0.01,  # initial learning rate\n",
    "    'lrf': 0.01,  # final learning rate\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'verbose': True,\n",
    "    'save': True,\n",
    "    'exist_ok': True\n",
    "}\n",
    "\n",
    "print(\"\\n[4] Training Hyperparameters\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Configuration (to be used in notebook 03):\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Configuration complete\")\n",
    "print(\"Ready for training in notebook 03_training.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d4f85",
   "metadata": {},
   "source": [
    "Stage 5: Training Hyperparameters Definition\n",
    "\n",
    "This stage defines all hyperparameters that control the training process executed in notebook 03. Optimized for lightweight academic dataset.\n",
    "\n",
    "Key hyperparameters:\n",
    "- epochs: 20 complete passes through training data (reduced from 50 for small dataset)\n",
    "- batch_size: 8 images per gradient update (reduced from 16 for small dataset)\n",
    "- imgsz: Input image size 416x416 pixels\n",
    "- patience: Early stopping at 5 epochs without improvement (reduced from 10)\n",
    "- device: GPU (cuda) or CPU for training\n",
    "- seed: Fixed random seed 42 for reproducibility\n",
    "- learning rate (lr0, lrf): Initial 0.01, final 0.001 with decay schedule\n",
    "- momentum: SGD momentum 0.937 for optimization\n",
    "- weight_decay: L2 regularization 0.0005 to prevent overfitting\n",
    "- warmup: Gradual learning rate increase in first 2 epochs\n",
    "\n",
    "For academic lightweight dataset:\n",
    "- Smaller number of epochs prevents overfitting\n",
    "- Reduced batch size matches small dataset size\n",
    "- Shorter early stopping patience\n",
    "- Total training time: 5-15 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
