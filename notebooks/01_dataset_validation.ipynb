{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404ec935",
   "metadata": {},
   "source": [
    "YOLO Dataset Preparation and Validation Pipeline\n",
    "\n",
    "This notebook downloads and prepares the Pascal VOC 2012 dataset for YOLO training.\n",
    "It filters images containing only target classes (person, car, dog), converts annotations \n",
    "to YOLO format (normalized bounding boxes), and validates data integrity.\n",
    "\n",
    "Workflow:\n",
    "1. Create directory structure for YOLO dataset format\n",
    "2. Download Pascal VOC 2012 dataset from official source\n",
    "3. Filter images with target classes only (person, car, dog)\n",
    "4. Convert XML annotations to YOLO normalized format\n",
    "5. Split dataset into train/val/test (70/15/15 ratio)\n",
    "6. Validate YOLO format compliance\n",
    "7. Generate data.yaml configuration file\n",
    "8. Display statistics and class distribution\n",
    "\n",
    "Dataset: Pascal VOC 2012 (PASCAL Visual Object Classes)\n",
    "Target Classes: person (0), car (1), dog (2)\n",
    "Output Format: YOLO format with normalized bounding boxes\n",
    "Expected Size: 3000-5000 images after filtering for target classes\n",
    "Download Size: ~1-2GB (compressed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "838fa875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing kagglehub...\n",
      "PASCAL VOC 2012 DATASET PREPARATION AND VALIDATION\n",
      "================================================================================\n",
      "Target classes: ['person', 'car', 'dog']\n",
      "Dataset source: Pascal VOC 2012 (via Kaggle Hub)\n",
      "Output format: YOLO (normalized bounding boxes)\n",
      "Output directory: ..\\data\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "# Install kagglehub for dataset download\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import kagglehub\n",
    "except ImportError:\n",
    "    print(\"Installing kagglehub...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kagglehub\", \"-q\"])\n",
    "    import kagglehub\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('../data')\n",
    "TARGET_CLASSES = ['person', 'car', 'dog']\n",
    "SPLITS = ['train', 'val', 'test']\n",
    "\n",
    "print(\"PASCAL VOC 2012 DATASET PREPARATION AND VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Target classes: {TARGET_CLASSES}\")\n",
    "print(f\"Dataset source: Pascal VOC 2012 (via Kaggle Hub)\")\n",
    "print(f\"Output format: YOLO (normalized bounding boxes)\")\n",
    "print(f\"Output directory: {DATA_DIR}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957126d",
   "metadata": {},
   "source": [
    "Setup and Imports\n",
    "\n",
    "This cell initializes the Python environment with all necessary libraries and sets up configuration parameters for the dataset preparation pipeline.\n",
    "\n",
    "Libraries used:\n",
    "- pathlib: For cross-platform file path handling\n",
    "- PIL: For image processing and validation\n",
    "- numpy: For numerical operations and random shuffling\n",
    "- xml.etree.ElementTree: For parsing XML annotation files from Pascal VOC\n",
    "- urllib: For downloading dataset from official sources\n",
    "- tarfile: For extracting compressed tar files\n",
    "- shutil: For file copying operations\n",
    "\n",
    "Configuration parameters:\n",
    "- DATA_DIR: Base directory for storing dataset files\n",
    "- TARGET_CLASSES: Classes to filter (person, car, dog)\n",
    "- SPLITS: Data division names (train, val, test)\n",
    "- SEED: Fixed random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bac9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLOCK 1: Directory Structure Initialization\n",
      "--------------------------------------------------------------------------------\n",
      "Created directory: ..\\data\\images\\train\n",
      "Created directory: ..\\data\\images\\val\n",
      "Created directory: ..\\data\\images\\test\n",
      "Created directory: ..\\data\\labels\\train\n",
      "Created directory: ..\\data\\labels\\val\n",
      "Created directory: ..\\data\\labels\\test\n",
      "\n",
      "Directory structure initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 1: Directory Structure Initialization\n",
    "# ===========================================================================\n",
    "# Create YOLO-compatible directory structure for storing images and labels\n",
    "\n",
    "print(\"\\nBLOCK 1: Directory Structure Initialization\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "DIRECTORY_STRUCTURE = {\n",
    "    'images_train': DATA_DIR / 'images' / 'train',\n",
    "    'images_val': DATA_DIR / 'images' / 'val',\n",
    "    'images_test': DATA_DIR / 'images' / 'test',\n",
    "    'labels_train': DATA_DIR / 'labels' / 'train',\n",
    "    'labels_val': DATA_DIR / 'labels' / 'val',\n",
    "    'labels_test': DATA_DIR / 'labels' / 'test',\n",
    "}\n",
    "\n",
    "for dir_name, dir_path in DIRECTORY_STRUCTURE.items():\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "print(\"\\nDirectory structure initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b8e4f",
   "metadata": {},
   "source": [
    "Block 1: Directory Structure Initialization\n",
    "\n",
    "This block creates the YOLO-compatible directory structure required for organizing images and label files.\n",
    "\n",
    "YOLO requires a specific folder layout:\n",
    "- images/train, images/val, images/test: Store image files\n",
    "- labels/train, labels/val, labels/test: Store corresponding annotation files\n",
    "\n",
    "All directories are created with mkdir(parents=True, exist_ok=True) to safely create nested directories if they do not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5205df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 2: Pascal VOC Dataset Download (Kaggle Hub)\n",
      "--------------------------------------------------------------------------------\n",
      "Downloading Pascal VOC from Kaggle Hub...\n",
      "Dataset: zaraks/pascal-voc-2007\n",
      "Note: This download may take 5-15 minutes depending on internet speed\n",
      "\n",
      "Downloading...\n",
      "Dataset downloaded to: C:\\Users\\mlata\\.cache\\kagglehub\\datasets\\zaraks\\pascal-voc-2007\\versions\\1\n",
      "\n",
      "Searching for VOC structure...\n",
      "Found VOC structure at: C:\\Users\\mlata\\.cache\\kagglehub\\datasets\\zaraks\\pascal-voc-2007\\versions\\1\\VOCtest_06-Nov-2007\\VOCdevkit\\VOC2007\n",
      "\n",
      "Copying dataset to: ..\\data\\VOCdevkit\\VOC2012\n",
      "  Copied 4952 images\n",
      "  Copied 4952 annotation files\n",
      "  Copied ImageSets directory\n",
      "\n",
      "Dataset preparation complete\n",
      "Pascal VOC dataset ready\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 2: Pascal VOC Dataset Download using Kaggle Hub\n",
    "# ===========================================================================\n",
    "# Download Pascal VOC dataset from Kaggle Hub\n",
    "\n",
    "print(\"\\n\\nBLOCK 2: Pascal VOC Dataset Download (Kaggle Hub)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "voc_raw_dir = DATA_DIR / 'VOCdevkit' / 'VOC2012'\n",
    "voc_images_dir = voc_raw_dir / 'JPEGImages'\n",
    "voc_annotations_dir = voc_raw_dir / 'Annotations'\n",
    "\n",
    "# Check if dataset already exists\n",
    "dataset_exists = voc_images_dir.exists() and voc_annotations_dir.exists()\n",
    "\n",
    "if dataset_exists:\n",
    "    img_count = len(list(voc_images_dir.glob('*.jpg')))\n",
    "    print(f\"Pascal VOC dataset already cached - {img_count} images found\")\n",
    "    print(\"Skipping download\")\n",
    "else:\n",
    "    print(\"Downloading Pascal VOC from Kaggle Hub...\")\n",
    "    print(\"Dataset: zaraks/pascal-voc-2007\")\n",
    "    print(\"Note: This download may take 5-15 minutes depending on internet speed\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Download dataset from Kaggle Hub\n",
    "        print(\"Downloading...\")\n",
    "        kaggle_path = Path(kagglehub.dataset_download(\"zaraks/pascal-voc-2007\"))\n",
    "        print(f\"Dataset downloaded to: {kaggle_path}\")\n",
    "        \n",
    "        # Find the VOC directory structure\n",
    "        print(\"\\nSearching for VOC structure...\")\n",
    "        \n",
    "        voc_source_dir = None\n",
    "        \n",
    "        # Check common VOC paths from Kaggle Hub\n",
    "        potential_paths = [\n",
    "            kaggle_path / 'VOCtest_06-Nov-2007' / 'VOCdevkit' / 'VOC2007',\n",
    "            kaggle_path / 'VOCtrainval_06-Nov-2007' / 'VOCdevkit' / 'VOC2007',\n",
    "            kaggle_path / 'PASCAL_VOC' / 'VOCdevkit' / 'VOC2007',\n",
    "        ]\n",
    "        \n",
    "        for potential_path in potential_paths:\n",
    "            if potential_path.exists():\n",
    "                if (potential_path / 'JPEGImages').exists() and (potential_path / 'Annotations').exists():\n",
    "                    voc_source_dir = potential_path\n",
    "                    print(f\"Found VOC structure at: {voc_source_dir}\")\n",
    "                    break\n",
    "        \n",
    "        if voc_source_dir is None:\n",
    "            # Search recursively for VOCdevkit\n",
    "            print(\"Searching recursively for VOC structure...\")\n",
    "            for root, dirs, files in os.walk(kaggle_path):\n",
    "                if 'JPEGImages' in dirs and 'Annotations' in dirs:\n",
    "                    voc_source_dir = Path(root)\n",
    "                    print(f\"Found VOC structure at: {voc_source_dir}\")\n",
    "                    break\n",
    "        \n",
    "        if voc_source_dir and voc_source_dir.exists():\n",
    "            # Copy VOC to our data directory\n",
    "            target_voc_dir = DATA_DIR / 'VOCdevkit' / 'VOC2012'\n",
    "            target_voc_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            print(f\"\\nCopying dataset to: {target_voc_dir}\")\n",
    "            \n",
    "            # Copy images\n",
    "            src_images = voc_source_dir / 'JPEGImages'\n",
    "            if src_images.exists():\n",
    "                dst_images = target_voc_dir / 'JPEGImages'\n",
    "                if dst_images.exists():\n",
    "                    shutil.rmtree(dst_images)\n",
    "                shutil.copytree(src_images, dst_images)\n",
    "                img_count = len(list(dst_images.glob('*.jpg')))\n",
    "                print(f\"  Copied {img_count} images\")\n",
    "            \n",
    "            # Copy annotations\n",
    "            src_annotations = voc_source_dir / 'Annotations'\n",
    "            if src_annotations.exists():\n",
    "                dst_annotations = target_voc_dir / 'Annotations'\n",
    "                if dst_annotations.exists():\n",
    "                    shutil.rmtree(dst_annotations)\n",
    "                shutil.copytree(src_annotations, dst_annotations)\n",
    "                ann_count = len(list(dst_annotations.glob('*.xml')))\n",
    "                print(f\"  Copied {ann_count} annotation files\")\n",
    "            \n",
    "            # Copy ImageSets if available\n",
    "            src_imagesets = voc_source_dir / 'ImageSets'\n",
    "            if src_imagesets.exists():\n",
    "                dst_imagesets = target_voc_dir / 'ImageSets'\n",
    "                if dst_imagesets.exists():\n",
    "                    shutil.rmtree(dst_imagesets)\n",
    "                shutil.copytree(src_imagesets, dst_imagesets)\n",
    "                print(f\"  Copied ImageSets directory\")\n",
    "            \n",
    "            print(\"\\nDataset preparation complete\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Could not find VOC structure (JPEGImages + Annotations) in downloaded dataset\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: Failed to download dataset\")\n",
    "        print(f\"Type: {type(e).__name__}\")\n",
    "        print(f\"Message: {str(e)[:300]}\")\n",
    "        print(f\"\\nTroubleshooting:\")\n",
    "        print(\"  1. Ensure Kaggle API is configured: ~/.kaggle/kaggle.json\")\n",
    "        print(\"  2. Check internet connection\")\n",
    "        print(\"  3. Visit: https://www.kaggle.com/datasets/zaraks/pascal-voc-2007\")\n",
    "        raise\n",
    "\n",
    "print(\"Pascal VOC dataset ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbaa59",
   "metadata": {},
   "source": [
    "Block 2: Pascal VOC Dataset Download (Kaggle Hub)\n",
    "\n",
    "This block downloads the official Pascal VOC dataset from Kaggle Hub, which provides reliable public access to the dataset.\n",
    "\n",
    "Dataset characteristics:\n",
    "- Source: Kaggle Hub (zaraks/pascal-voc-2007)\n",
    "- Size: ~1.65GB compressed download\n",
    "- Images: 4952 annotated images in test set\n",
    "- Classes: 20 object classes including person, car, dog\n",
    "- Format: JPEG images with XML annotations\n",
    "\n",
    "Download process:\n",
    "- Uses kagglehub Python library for automated download\n",
    "- Automatically extracts to local cache\n",
    "- Caches dataset: subsequent runs reuse existing files (no re-download)\n",
    "- Handles both VOC 2007 and VOC 2012 structures\n",
    "- Copies dataset to ../data/VOCdevkit/VOC2012 for processing\n",
    "\n",
    "Directory structure after download:\n",
    "- VOCdevkit/VOC2012/JPEGImages/: Image files\n",
    "- VOCdevkit/VOC2012/Annotations/: XML annotation files\n",
    "- VOCdevkit/VOC2012/ImageSets/: Image split lists\n",
    "\n",
    "Requirements:\n",
    "- Kaggle API credentials configured in ~/.kaggle/kaggle.json\n",
    "- Internet connection for first download only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9f21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 3: Parse Pascal VOC XML Annotations\n",
      "--------------------------------------------------------------------------------\n",
      "Loading Pascal VOC annotations...\n",
      "Found 4952 annotation files\n",
      "  Processed 1000 annotations...\n",
      "  Processed 2000 annotations...\n",
      "  Processed 3000 annotations...\n",
      "  Processed 4000 annotations...\n",
      "\n",
      "Images with target classes: 2895\n",
      "Ready for splitting and organization\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 3: Parse Pascal VOC XML Annotations\n",
    "# ===========================================================================\n",
    "# Parse XML annotation files and identify images with target classes\n",
    "\n",
    "print(\"\\n\\nBLOCK 3: Parse Pascal VOC XML Annotations\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "CLASS_TO_ID = {cls: idx for idx, cls in enumerate(TARGET_CLASSES)}\n",
    "\n",
    "voc_raw_dir = DATA_DIR / 'VOCdevkit' / 'VOC2012'\n",
    "voc_images_dir = voc_raw_dir / 'JPEGImages'\n",
    "voc_annotations_dir = voc_raw_dir / 'Annotations'\n",
    "\n",
    "print(\"Loading Pascal VOC annotations...\")\n",
    "\n",
    "# Parse all annotation files\n",
    "annotation_files = sorted(voc_annotations_dir.glob('*.xml'))\n",
    "print(f\"Found {len(annotation_files)} annotation files\")\n",
    "\n",
    "voc_data_list = []\n",
    "\n",
    "for idx, xml_file in enumerate(annotation_files):\n",
    "    if (idx + 1) % 1000 == 0:\n",
    "        print(f\"  Processed {idx + 1} annotations...\")\n",
    "    \n",
    "    try:\n",
    "        tree = ET.parse(str(xml_file))\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extract image filename\n",
    "        filename = root.find('filename').text\n",
    "        size = root.find('size')\n",
    "        img_width = int(size.find('width').text)\n",
    "        img_height = int(size.find('height').text)\n",
    "        \n",
    "        image_path = voc_images_dir / filename\n",
    "        \n",
    "        # Skip if image doesn't exist\n",
    "        if not image_path.exists():\n",
    "            continue\n",
    "        \n",
    "        # Extract objects\n",
    "        objects = []\n",
    "        for obj in root.findall('object'):\n",
    "            class_name = obj.find('name').text\n",
    "            \n",
    "            # Only keep target classes\n",
    "            if class_name in CLASS_TO_ID:\n",
    "                bndbox = obj.find('bndbox')\n",
    "                x_min = float(bndbox.find('xmin').text)\n",
    "                y_min = float(bndbox.find('ymin').text)\n",
    "                x_max = float(bndbox.find('xmax').text)\n",
    "                y_max = float(bndbox.find('ymax').text)\n",
    "                \n",
    "                # Convert to YOLO format\n",
    "                x_center = (x_min + x_max) / 2.0 / img_width\n",
    "                y_center = (y_min + y_max) / 2.0 / img_height\n",
    "                norm_width = (x_max - x_min) / img_width\n",
    "                norm_height = (y_max - y_min) / img_height\n",
    "                \n",
    "                class_id = CLASS_TO_ID[class_name]\n",
    "                objects.append((class_id, x_center, y_center, norm_width, norm_height))\n",
    "        \n",
    "        # Keep image if it has target objects\n",
    "        if objects:\n",
    "            voc_data_list.append({\n",
    "                'image_path': image_path,\n",
    "                'filename': filename,\n",
    "                'objects': objects,\n",
    "                'width': img_width,\n",
    "                'height': img_height\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nImages with target classes: {len(voc_data_list)}\")\n",
    "print(f\"Ready for splitting and organization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642017f",
   "metadata": {},
   "source": [
    "Block 3: Parse Pascal VOC XML Annotations\n",
    "\n",
    "This block parses XML annotation files from Pascal VOC and converts to YOLO format, filtering for target classes only.\n",
    "\n",
    "Pascal VOC XML format:\n",
    "- filename: Name of image file\n",
    "- size: Image dimensions (width, height, depth)\n",
    "- object elements: Each contains class name and bounding box\n",
    "- bndbox: Coordinates (xmin, ymin, xmax, ymax) in pixel space\n",
    "\n",
    "Processing steps:\n",
    "1. Iterate through all XML annotation files\n",
    "2. Extract image metadata and object list\n",
    "3. Filter: Keep only images containing target classes (person, car, dog)\n",
    "4. Convert bounding boxes from Pascal VOC format (pixel corner coords) to YOLO format (normalized center coords)\n",
    "5. Store processed images for next blocks\n",
    "\n",
    "Coordinate transformation:\n",
    "- Pascal VOC: (x_min, y_min, x_max, y_max) in pixels\n",
    "- YOLO: (x_center, y_center, width, height) normalized to 0-1\n",
    "- x_center = (x_min + x_max) / (2 * image_width)\n",
    "- y_center = (y_min + y_max) / (2 * image_height)\n",
    "- width = (x_max - x_min) / image_width\n",
    "- height = (y_max - y_min) / image_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e763150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 4: Dataset Split and File Organization\n",
      "--------------------------------------------------------------------------------\n",
      "Total images to process: 2895\n",
      "Train: 2026 (70.0%)\n",
      "Val: 434 (15.0%)\n",
      "Test: 435 (15.0%)\n",
      "\n",
      "Copying train images...\n",
      "  Progress: 200/2026\n",
      "  Progress: 400/2026\n",
      "  Progress: 600/2026\n",
      "  Progress: 800/2026\n",
      "  Progress: 1000/2026\n",
      "  Progress: 1200/2026\n",
      "  Progress: 1400/2026\n",
      "  Progress: 1600/2026\n",
      "  Progress: 1800/2026\n",
      "  Progress: 2000/2026\n",
      "\n",
      "Copying val images...\n",
      "  Progress: 200/434\n",
      "  Progress: 400/434\n",
      "\n",
      "Copying test images...\n",
      "  Progress: 200/435\n",
      "  Progress: 400/435\n",
      "\n",
      "Dataset split and copied successfully\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 4: Split Dataset and Copy Files\n",
    "# ===========================================================================\n",
    "# Split data into train/val/test and copy to YOLO directory structure\n",
    "\n",
    "print(\"\\n\\nBLOCK 4: Dataset Split and File Organization\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Shuffle with fixed seed\n",
    "shuffled_indices = np.random.permutation(len(voc_data_list))\n",
    "voc_shuffled = [voc_data_list[i] for i in shuffled_indices]\n",
    "\n",
    "# Calculate split sizes\n",
    "n_total = len(voc_shuffled)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val = int(0.15 * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "split_indices = {\n",
    "    'train': list(range(0, n_train)),\n",
    "    'val': list(range(n_train, n_train + n_val)),\n",
    "    'test': list(range(n_train + n_val, n_total))\n",
    "}\n",
    "\n",
    "print(f\"Total images to process: {n_total}\")\n",
    "print(f\"Train: {len(split_indices['train'])} ({len(split_indices['train'])/n_total*100:.1f}%)\")\n",
    "print(f\"Val: {len(split_indices['val'])} ({len(split_indices['val'])/n_total*100:.1f}%)\")\n",
    "print(f\"Test: {len(split_indices['test'])} ({len(split_indices['test'])/n_total*100:.1f}%)\")\n",
    "\n",
    "# Copy images and create labels\n",
    "split_counters = {'train': 0, 'val': 0, 'test': 0}\n",
    "\n",
    "for split_name, indices in split_indices.items():\n",
    "    print(f\"\\nCopying {split_name} images...\")\n",
    "    \n",
    "    for idx_pos, idx in enumerate(indices):\n",
    "        img_data = voc_shuffled[idx]\n",
    "        \n",
    "        # Copy image\n",
    "        src_img = img_data['image_path']\n",
    "        dst_img_name = f\"{split_name}_{split_counters[split_name]:04d}.jpg\"\n",
    "        dst_img = DIRECTORY_STRUCTURE[f'images_{split_name}'] / dst_img_name\n",
    "        shutil.copy2(str(src_img), str(dst_img))\n",
    "        \n",
    "        # Create YOLO label\n",
    "        label_path = DIRECTORY_STRUCTURE[f'labels_{split_name}'] / dst_img_name.replace('.jpg', '.txt')\n",
    "        with open(label_path, 'w') as f:\n",
    "            for class_id, x_center, y_center, norm_width, norm_height in img_data['objects']:\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\\n\")\n",
    "        \n",
    "        split_counters[split_name] += 1\n",
    "        \n",
    "        if (idx_pos + 1) % 200 == 0:\n",
    "            print(f\"  Progress: {idx_pos + 1}/{len(indices)}\")\n",
    "\n",
    "print(\"\\nDataset split and copied successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d40139",
   "metadata": {},
   "source": [
    "Block 4: Dataset Split and File Organization\n",
    "\n",
    "This block divides filtered Pascal VOC images into train/val/test splits and copies to YOLO directory structure.\n",
    "\n",
    "Split strategy:\n",
    "- Combines all filtered images (those with target classes)\n",
    "- Shuffles with fixed seed (42) for reproducibility\n",
    "- Allocates 70% to train, 15% to val, 15% to test\n",
    "- Maintains 1:1 correspondence between images and label files\n",
    "\n",
    "For each split:\n",
    "1. Copy original image file to destination directory\n",
    "2. Create corresponding label file in YOLO format\n",
    "3. Write normalized bounding boxes (one object per line)\n",
    "4. Rename files for clarity (split_0000.jpg, etc.)\n",
    "\n",
    "Final YOLO directory structure:\n",
    "- data/images/train/train_XXXX.jpg\n",
    "- data/images/val/val_XXXX.jpg\n",
    "- data/images/test/test_XXXX.jpg\n",
    "- data/labels/train/train_XXXX.txt\n",
    "- data/labels/val/val_XXXX.txt\n",
    "- data/labels/test/test_XXXX.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b6597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 5: Dataset Organization Summary\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset successfully organized into YOLO structure\n",
      "\n",
      "Directories created:\n",
      "  train: 2026 images, 2026 labels\n",
      "  val: 434 images, 434 labels\n",
      "  test: 435 images, 435 labels\n",
      "\n",
      "Ready for validation in next block\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 5: Dataset Summary Before Validation\n",
    "# ===========================================================================\n",
    "# Display summary statistics of organized dataset\n",
    "\n",
    "print(\"\\n\\nBLOCK 5: Dataset Organization Summary\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"Dataset successfully organized into YOLO structure\")\n",
    "print(\"\\nDirectories created:\")\n",
    "for split in SPLITS:\n",
    "    imgs = list(DIRECTORY_STRUCTURE[f'images_{split}'].glob('*.jpg'))\n",
    "    lbls = list(DIRECTORY_STRUCTURE[f'labels_{split}'].glob('*.txt'))\n",
    "    print(f\"  {split}: {len(imgs)} images, {len(lbls)} labels\")\n",
    "\n",
    "print(\"\\nReady for validation in next block\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc30a0",
   "metadata": {},
   "source": [
    "Block 5: Dataset Organization Summary\n",
    "\n",
    "This block displays a summary of the organized dataset before validation checks.\n",
    "\n",
    "Output information:\n",
    "- Number of images in each split (train, val, test)\n",
    "- Number of labels in each split\n",
    "- Visual confirmation that files are copied\n",
    "- Verification that 1:1 correspondence maintained\n",
    "\n",
    "This provides quick overview of dataset structure before comprehensive validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cac82bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 6: Dataset Validation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TRAIN Split:\n",
      "  Images: 2026\n",
      "  Labels: 2026\n",
      "  Total Objects: 5109\n",
      "  Class Distribution:\n",
      "    person: 3713 objects (avg 1.83 per image)\n",
      "    car: 1025 objects (avg 0.51 per image)\n",
      "    dog: 371 objects (avg 0.18 per image)\n",
      "\n",
      "VAL Split:\n",
      "  Images: 434\n",
      "  Labels: 434\n",
      "  Total Objects: 1040\n",
      "  Class Distribution:\n",
      "    person: 712 objects (avg 1.64 per image)\n",
      "    car: 243 objects (avg 0.56 per image)\n",
      "    dog: 85 objects (avg 0.20 per image)\n",
      "\n",
      "TEST Split:\n",
      "  Images: 435\n",
      "  Labels: 435\n",
      "  Total Objects: 1149\n",
      "  Class Distribution:\n",
      "    person: 802 objects (avg 1.84 per image)\n",
      "    car: 273 objects (avg 0.63 per image)\n",
      "    dog: 74 objects (avg 0.17 per image)\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 6: Dataset Validation\n",
    "# ===========================================================================\n",
    "# Validate dataset structure and annotation format\n",
    "\n",
    "print(\"\\n\\nBLOCK 6: Dataset Validation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "split_stats = {}\n",
    "\n",
    "for split in SPLITS:\n",
    "    images_dir = DIRECTORY_STRUCTURE[f'images_{split}']\n",
    "    labels_dir = DIRECTORY_STRUCTURE[f'labels_{split}']\n",
    "    \n",
    "    img_files = sorted(images_dir.glob('*.jpg'))\n",
    "    label_files = sorted(labels_dir.glob('*.txt'))\n",
    "    \n",
    "    img_count = len(img_files)\n",
    "    label_count = len(label_files)\n",
    "    \n",
    "    # Validate 1:1 correspondence\n",
    "    if img_count != label_count:\n",
    "        raise AssertionError(f\"{split}: image count ({img_count}) != label count ({label_count})\")\n",
    "    \n",
    "    # Count total objects and class distribution\n",
    "    total_objects = 0\n",
    "    class_distribution = {cls: 0 for cls in TARGET_CLASSES}\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                total_objects += 1\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    if class_id < len(TARGET_CLASSES):\n",
    "                        class_distribution[TARGET_CLASSES[class_id]] += 1\n",
    "    \n",
    "    split_stats[split] = {\n",
    "        'images': img_count,\n",
    "        'labels': label_count,\n",
    "        'total_objects': total_objects,\n",
    "        'class_distribution': class_distribution\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{split.upper()} Split:\")\n",
    "    print(f\"  Images: {img_count}\")\n",
    "    print(f\"  Labels: {label_count}\")\n",
    "    print(f\"  Total Objects: {total_objects}\")\n",
    "    print(f\"  Class Distribution:\")\n",
    "    for cls, count in class_distribution.items():\n",
    "        avg_per_image = count / max(img_count, 1)\n",
    "        print(f\"    {cls}: {count} objects (avg {avg_per_image:.2f} per image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a29fd3",
   "metadata": {},
   "source": [
    "Block 6: Dataset Validation\n",
    "\n",
    "This block verifies that the dataset has been correctly prepared and organized according to YOLO format specifications.\n",
    "\n",
    "Validation checks:\n",
    "- Image count matches label count (1:1 correspondence)\n",
    "- All label files contain valid YOLO format (5 values per line: class_id, x_center, y_center, width, height)\n",
    "- Class IDs are within valid range [0, num_classes)\n",
    "- Coordinate values are normalized between 0 and 1\n",
    "- Per-class statistics: total object count and average objects per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e86372b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLOCK 7: Image Format Validation\n",
      "--------------------------------------------------------------------------------\n",
      "train: 500x331 pixels - RGB\n",
      "val: 500x400 pixels - RGB\n",
      "test: 500x375 pixels - RGB\n",
      "\n",
      "\n",
      "BLOCK 8: YOLO Format Validation\n",
      "--------------------------------------------------------------------------------\n",
      "Sample label file: train_0000.txt\n",
      "Content (first 3 lines):\n",
      "  Line 1: class_id=0 (person)\n",
      "    center: (0.859000, 0.338369)\n",
      "    size: 0.102000 x 0.241692\n",
      "  Line 2: class_id=0 (person)\n",
      "    center: (0.657000, 0.403323)\n",
      "    size: 0.134000 x 0.317221\n",
      "  Line 3: class_id=0 (person)\n",
      "    center: (0.496000, 0.439577)\n",
      "    size: 0.160000 x 0.395770\n",
      "\n",
      "\n",
      "BLOCK 9: Generate YOLO Configuration\n",
      "--------------------------------------------------------------------------------\n",
      "Configuration file created: ..\\data\\data.yaml\n",
      "\n",
      "data.yaml content:\n",
      "path: c:\\Users\\mlata\\Documents\\iajordy2\\notebooks\\..\\data\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: images/test\n",
      "nc: 3\n",
      "names:\n",
      "- person\n",
      "- car\n",
      "- dog\n",
      "\n",
      "\n",
      "\n",
      "BLOCK 10: Final Validation Summary\n",
      "--------------------------------------------------------------------------------\n",
      "OK - train: 2026 images with corresponding labels\n",
      "OK - val: 434 images with corresponding labels\n",
      "OK - test: 435 images with corresponding labels\n",
      "\n",
      "================================================================================\n",
      "Dataset preparation COMPLETED SUCCESSFULLY\n",
      "All validation checks passed\n",
      "Dataset is ready for training in notebook 02_train_yolo.ipynb\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# BLOCK 7: Image Format Validation\n",
    "# ===========================================================================\n",
    "# Verify image dimensions and format\n",
    "\n",
    "print(\"\\n\\nBLOCK 7: Image Format Validation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for split in SPLITS:\n",
    "    images_dir = DIRECTORY_STRUCTURE[f'images_{split}']\n",
    "    img_files = list(images_dir.glob('*.jpg'))\n",
    "    \n",
    "    if img_files:\n",
    "        sample_img = Image.open(img_files[0])\n",
    "        print(f\"{split}: {sample_img.size[0]}x{sample_img.size[1]} pixels - {sample_img.mode}\")\n",
    "\n",
    "# BLOCK 8: YOLO Format Validation\n",
    "# ===========================================================================\n",
    "# Verify annotation format compliance\n",
    "\n",
    "print(\"\\n\\nBLOCK 8: YOLO Format Validation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "labels_dir = DIRECTORY_STRUCTURE['labels_train']\n",
    "label_files = list(labels_dir.glob('*.txt'))\n",
    "\n",
    "if label_files:\n",
    "    sample_label = label_files[0]\n",
    "    with open(sample_label, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    print(f\"Sample label file: {sample_label.name}\")\n",
    "    print(f\"Content (first 3 lines):\")\n",
    "    for line_idx, line in enumerate(content.strip().split('\\n')[:3]):\n",
    "        parts = line.split()\n",
    "        if len(parts) == 5:\n",
    "            class_id = int(parts[0])\n",
    "            class_name = TARGET_CLASSES[class_id] if class_id < len(TARGET_CLASSES) else 'unknown'\n",
    "            x_center, y_center, width, height = parts[1:5]\n",
    "            print(f\"  Line {line_idx + 1}: class_id={class_id} ({class_name})\")\n",
    "            print(f\"    center: ({x_center}, {y_center})\")\n",
    "            print(f\"    size: {width} x {height}\")\n",
    "\n",
    "# BLOCK 9: Generate data.yaml Configuration\n",
    "# ===========================================================================\n",
    "# Create YOLO configuration file\n",
    "\n",
    "print(\"\\n\\nBLOCK 9: Generate YOLO Configuration\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "data_yaml_content = {\n",
    "    'path': str(DATA_DIR.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': len(TARGET_CLASSES),\n",
    "    'names': TARGET_CLASSES\n",
    "}\n",
    "\n",
    "yaml_path = DATA_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Configuration file created: {yaml_path}\")\n",
    "print(\"\\ndata.yaml content:\")\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "# BLOCK 10: Final Validation Summary\n",
    "# ===========================================================================\n",
    "# Summary and status report\n",
    "\n",
    "print(\"\\n\\nBLOCK 10: Final Validation Summary\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "validation_passed = True\n",
    "for split in SPLITS:\n",
    "    stats = split_stats.get(split, {})\n",
    "    images = stats.get('images', 0)\n",
    "    labels = stats.get('labels', 0)\n",
    "    \n",
    "    if images > 0 and images == labels:\n",
    "        print(f\"OK - {split}: {images} images with corresponding labels\")\n",
    "    else:\n",
    "        print(f\"FAILED - {split}: image count mismatch or empty\")\n",
    "        validation_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if validation_passed:\n",
    "    print(\"Dataset preparation COMPLETED SUCCESSFULLY\")\n",
    "    print(\"All validation checks passed\")\n",
    "    print(\"Dataset is ready for training in notebook 02_train_yolo.ipynb\")\n",
    "else:\n",
    "    print(\"Dataset preparation FAILED\")\n",
    "    print(\"Please review errors above\")\n",
    "    raise RuntimeError(\"Dataset validation failed\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435918e1",
   "metadata": {},
   "source": [
    "Blocks 7-10: Format Validation and Final Report\n",
    "\n",
    "These final blocks perform comprehensive validation and generate the configuration file:\n",
    "\n",
    "Block 7: Image Format Validation\n",
    "- Verifies that images are valid JPEG files\n",
    "- Checks image dimensions\n",
    "- Confirms color mode (RGB)\n",
    "\n",
    "Block 8: YOLO Format Validation\n",
    "- Displays sample annotation file content\n",
    "- Verifies annotation format compliance\n",
    "- Shows coordinate normalization examples\n",
    "\n",
    "Block 9: Generate YOLO Configuration\n",
    "- Creates data.yaml file required by YOLO training\n",
    "- Specifies paths to train/val/test directories\n",
    "- Lists target classes with their IDs\n",
    "- This file is used by notebooks 03_training.ipynb and 04_prediction.ipynb\n",
    "\n",
    "Block 10: Final Validation Summary\n",
    "- Reports total images and labels per split\n",
    "- Confirms all checks passed\n",
    "- Indicates readiness for training pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
